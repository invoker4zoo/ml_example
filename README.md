# 数据挖掘与建模的步骤总结

通过数据竞赛和项目中的数据挖掘和建模的落地项目，总结出一套工程化的数据挖掘和建模方法，记录于此，希望之后不断的优化总结
提高数据分析与数据建模的效率，将其运用到不同的行业之中

## 问题的抽象表示

## 数据探索

   数据探索的目标是希望对我们手里面已有的数据有一个充分的理解，为我们接下来的工程步骤做充分的准备；很多时候，这一步都在数据挖掘的流程中被忽略了，
但当你在数据建模做过足够多的优化方法之后，就会发现，数据探索对于一个项目来言是非常重要的一步；为之后的模型优化做出了重要的准备工作。

   对数据的探索性分析一般用到padnas和matplotlib就足够达到分析和数据可视化的要求了，一般来说我们的探索方向集中在几个方面：

1. 了解数据中每个特征维度的实际意义的来源；特征维度是连续的数值型还是离散的特征型；特征维度的统计信息

*示例：df.describe()*

|id|full_sql|life_sq|floor|max_floor|
|-|-|-|-|-|
|count | 30471.000000 | 30471.000000 | 24088.000000 | 30304.000000 | 20899.000000 |
|mean  | 15237.917397 |    54.214269 |    34.403271 |     7.670803 |    12.558974 |
|std   |  8796.501536 |    38.031487 |    52.285733 |     5.319989 |     6.756550 |
|min   |     1.000000 |     0.000000 |     0.000000 |     0.000000 |     0.000000 |
|25%   |  7620.500000 |    38.000000 |    20.000000 |     3.000000 |     9.000000 |
|50%   | 15238.000000 |    49.000000 |    30.000000 |     6.500000 |    12.000000 |
|75%   | 22855.500000 |    63.000000 |    43.000000 |    11.000000 |    17.000000 |
|max   | 30473.000000 |  5326.000000 |  7478.000000 |    77.000000 |   117.000000 |

2. 特征维度的分布情况，是否为正常的正太分布，还是有显著的分类规律；

*示例：特征分布*

![distribution](static/price_dis.png)

3. 观察多个特征维度之间的相关性，链接特征维度之间的独立性和耦合情况；

*示例：相关性统计 *

![groupby](static/feature_relative.png)

4. 了解数据质量，查看数据缺失情况

* 示例：数据缺失值情况*

![miss_value](static/miss_value.png)

## 数据的预处理

1. 缺失数据的处理

缺失数据的处理一般可以粗略的分为三种情况：

  * 特征中的缺失数据的样本数量很小，可以是使用特征的平均值、众数或者由样本前后的样本数据进行填充；

  * 如果具有缺失值的特征与另一类型的特征的相关度非常的高，可以与其他特征之间建立简单的转换模型，由其他特征转化后进行填充；

* 特征中缺失值的比例非常的高，可以将特征值是否缺失作为另一个类别特征加入到数据维度之中

2. 通过数据探索过程中找到的数据集中的异常值，将数据集中的离群点剔除出数据集

3. 处理不平衡数据

  在数据集的构成中，很有可能会出现数据不平衡的情况，例如在反欺诈数据集中，我们就会发现有欺诈嫌疑的样本数量在整个数据集中的比例会非常的低，
这样的数据集对于模型的训练是非常不利的，所以需要我们对数据集进行重新的构造：采样、过采样、不同类别的数据使用不同权重等方式

## 特征工程

  理论上来说，特征工程应该也是属于数据预处理的一部分，不过该步骤实在是太过重要，所以将特征工程单独作为一个工作步骤提出

  在数据挖掘的竞赛中有一个经典的评论：数据挖掘的上限是由特征决定的，而模型和算法只是尽力的在逼近这个上限。由此可见特征工程在数据挖掘项目中的重要性。
  特征工程一般有以下的几种方式可以尝试：


